{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Augmentor in c:\\users\\chaya\\anaconda3\\lib\\site-packages (0.2.9)\n",
      "Requirement already satisfied: future>=0.16.0 in c:\\users\\chaya\\anaconda3\\lib\\site-packages (from Augmentor) (0.18.2)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\users\\chaya\\anaconda3\\lib\\site-packages (from Augmentor) (8.0.1)\n",
      "Requirement already satisfied: tqdm>=4.9.0 in c:\\users\\chaya\\anaconda3\\lib\\site-packages (from Augmentor) (4.50.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\chaya\\anaconda3\\lib\\site-packages (from Augmentor) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "!pip install Augmentor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path for train and test images\n",
    "\n",
    "data_dir_train = pathlib.Path(\"C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Test/\")\n",
    "data_dir_test = pathlib.Path(\"C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118 files belonging to 9 classes.\n",
      "Using 95 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(data_dir_train, \n",
    "                                        seed = 123, \n",
    "                                        image_size=(img_height, img_width), \n",
    "                                        validation_split=0.2, \n",
    "                                        subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118 files belonging to 9 classes.\n",
      "Using 23 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_ds = image_dataset_from_directory(data_dir_train, \n",
    "                                      seed = 123, \n",
    "                                      image_size=(img_height, img_width), \n",
    "                                      validation_split=0.2, \n",
    "                                      subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(type(class_names), class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actinic keratosis': 16,\n",
       " 'basal cell carcinoma': 16,\n",
       " 'dermatofibroma': 16,\n",
       " 'melanoma': 16,\n",
       " 'nevus': 16,\n",
       " 'pigmented benign keratosis': 16,\n",
       " 'seborrheic keratosis': 3,\n",
       " 'squamous cell carcinoma': 16,\n",
       " 'vascular lesion': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_size = {}\n",
    "\n",
    "for name in class_names:\n",
    "    class_size[name] = len(list(data_dir_train.glob(name+'/*.jpg')))\n",
    "\n",
    "class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumberOfSamples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actinic keratosis</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basal cell carcinoma</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dermatofibroma</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melanoma</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nevus</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pigmented benign keratosis</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seborrheic keratosis</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squamous cell carcinoma</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vascular lesion</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            NumberOfSamples\n",
       "actinic keratosis                        16\n",
       "basal cell carcinoma                     16\n",
       "dermatofibroma                           16\n",
       "melanoma                                 16\n",
       "nevus                                    16\n",
       "pigmented benign keratosis               16\n",
       "seborrheic keratosis                      3\n",
       "squamous cell carcinoma                  16\n",
       "vascular lesion                           3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df = pd.DataFrame(class_size.items(),index=list(class_size), columns = ['ClassName', 'NumberOfSamples'])\n",
    "class_df.drop(['ClassName'], axis = 1, inplace=True)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x208CE803160>:   2%|▏         | 9/500 [00:00<01:02,  7.90 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 114 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/actinic keratosis\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x208CE91E430>: 100%|██████████| 500/500 [00:06<00:00, 73.05 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/500 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 376 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/basal cell carcinoma\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x208CEA85280>: 100%|██████████| 500/500 [00:07<00:00, 67.97 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/500 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 95 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/dermatofibroma\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x208CE872490>: 100%|██████████| 500/500 [00:08<00:00, 61.69 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/500 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 438 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/melanoma\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=1024x768 at 0x208CE7D3580>: 100%|██████████| 500/500 [00:35<00:00, 13.93 Samples/s]                   \n",
      "Executing Pipeline:   0%|          | 0/500 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 357 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/nevus\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3072x2304 at 0x208CE90DE20>: 100%|██████████| 500/500 [00:33<00:00, 15.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/500 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 462 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/pigmented benign keratosis\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x208CEAF5DF0>: 100%|██████████| 500/500 [00:07<00:00, 63.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/500 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 77 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/seborrheic keratosis\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x768 at 0x208CEB02250>: 100%|██████████| 500/500 [00:16<00:00, 29.58 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/500 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 181 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/squamous cell carcinoma\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x208CE9187C0>: 100%|██████████| 500/500 [00:08<00:00, 62.15 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/500 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 139 image(s) found.\n",
      "Output directory set to C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/vascular lesion\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x208CEAC14F0>: 100%|██████████| 500/500 [00:07<00:00, 64.70 Samples/s]                  \n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "path_to_training_dataset = 'C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/'\n",
    "\n",
    "for i in class_names:\n",
    "    \n",
    "    p = Augmentor.Pipeline(path_to_training_dataset+i)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = pathlib.Path('C:/Users/chaya/Desktop/7th sem/major project/major_data_isic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    }
   ],
   "source": [
    "image_count_train = len(list(output_dir.glob('*/output/*.jpg')))\n",
    "print(image_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6739 files belonging to 9 classes.\n",
      "Using 5392 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  output_dir,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'training',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6739 files belonging to 9 classes.\n",
      "Using 1347 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  output_dir,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'validation',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 9\n",
    "\n",
    "# Model - Rescaling -> Conv2D -> MaxPooling2D -> Dropout -> Conv2D -> MaxPooling2D -> Dropout -> Conv2D -> MaxPooling2D -> Dropout -> Dense -> Dense\n",
    "model = Sequential()\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "model.add(Conv2D(16, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, 3, padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding='same'))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss = SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 180, 180, 16)      448       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 180, 180, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 90, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 90, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 90, 90, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3965056   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 3,989,801\n",
      "Trainable params: 3,989,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "281/281 [==============================] - 590s 1s/step - loss: 2.2180 - accuracy: 0.1379 - val_loss: 2.0135 - val_accuracy: 0.2372\n",
      "Epoch 2/30\n",
      "281/281 [==============================] - 443s 2s/step - loss: 1.9752 - accuracy: 0.2321 - val_loss: 1.8750 - val_accuracy: 0.2790\n",
      "Epoch 3/30\n",
      "281/281 [==============================] - 372s 1s/step - loss: 1.8621 - accuracy: 0.2692 - val_loss: 1.7729 - val_accuracy: 0.3026\n",
      "Epoch 4/30\n",
      "281/281 [==============================] - 296s 1s/step - loss: 1.7497 - accuracy: 0.3040 - val_loss: 1.7017 - val_accuracy: 0.3342\n",
      "Epoch 5/30\n",
      "281/281 [==============================] - 367s 1s/step - loss: 1.6672 - accuracy: 0.3318 - val_loss: 1.8873 - val_accuracy: 0.2595\n",
      "Epoch 6/30\n",
      "281/281 [==============================] - 395s 1s/step - loss: 1.5880 - accuracy: 0.3719 - val_loss: 1.5447 - val_accuracy: 0.4023\n",
      "Epoch 7/30\n",
      "281/281 [==============================] - 355s 1s/step - loss: 1.5230 - accuracy: 0.4095 - val_loss: 1.5743 - val_accuracy: 0.4068\n",
      "Epoch 8/30\n",
      "281/281 [==============================] - 320s 1s/step - loss: 1.3970 - accuracy: 0.4574 - val_loss: 1.4241 - val_accuracy: 0.4584\n",
      "Epoch 9/30\n",
      "281/281 [==============================] - 300s 1s/step - loss: 1.3184 - accuracy: 0.4931 - val_loss: 1.2942 - val_accuracy: 0.5158\n",
      "Epoch 10/30\n",
      "281/281 [==============================] - 328s 1s/step - loss: 1.2678 - accuracy: 0.5147 - val_loss: 1.3427 - val_accuracy: 0.4904\n",
      "Epoch 11/30\n",
      "281/281 [==============================] - 325s 1s/step - loss: 1.2424 - accuracy: 0.5200 - val_loss: 1.2263 - val_accuracy: 0.5487\n",
      "Epoch 12/30\n",
      "281/281 [==============================] - 312s 1s/step - loss: 1.1849 - accuracy: 0.5525 - val_loss: 1.3604 - val_accuracy: 0.5024\n",
      "Epoch 13/30\n",
      "281/281 [==============================] - 338s 1s/step - loss: 1.1232 - accuracy: 0.5737 - val_loss: 1.2294 - val_accuracy: 0.5394\n",
      "Epoch 14/30\n",
      "281/281 [==============================] - 297s 1s/step - loss: 1.0750 - accuracy: 0.5955 - val_loss: 1.1261 - val_accuracy: 0.5915\n",
      "Epoch 15/30\n",
      "281/281 [==============================] - 274s 977ms/step - loss: 1.0086 - accuracy: 0.6234 - val_loss: 1.0627 - val_accuracy: 0.6306\n",
      "Epoch 16/30\n",
      "281/281 [==============================] - 315s 1s/step - loss: 0.9808 - accuracy: 0.6394 - val_loss: 1.0119 - val_accuracy: 0.6466\n",
      "Epoch 17/30\n",
      "281/281 [==============================] - 303s 1s/step - loss: 0.9166 - accuracy: 0.6628 - val_loss: 1.0171 - val_accuracy: 0.6355\n",
      "Epoch 18/30\n",
      "281/281 [==============================] - 290s 1s/step - loss: 0.8353 - accuracy: 0.6941 - val_loss: 0.8749 - val_accuracy: 0.7005\n",
      "Epoch 19/30\n",
      "281/281 [==============================] - 301s 1s/step - loss: 0.7674 - accuracy: 0.7260 - val_loss: 0.8464 - val_accuracy: 0.7081\n",
      "Epoch 20/30\n",
      "281/281 [==============================] - 287s 1s/step - loss: 0.7161 - accuracy: 0.7453 - val_loss: 0.8142 - val_accuracy: 0.7241\n",
      "Epoch 21/30\n",
      "281/281 [==============================] - 275s 977ms/step - loss: 0.6228 - accuracy: 0.7794 - val_loss: 0.7531 - val_accuracy: 0.7472\n",
      "Epoch 22/30\n",
      "281/281 [==============================] - 317s 1s/step - loss: 0.5637 - accuracy: 0.7975 - val_loss: 0.6813 - val_accuracy: 0.7677\n",
      "Epoch 23/30\n",
      "281/281 [==============================] - 296s 1s/step - loss: 0.5322 - accuracy: 0.8068 - val_loss: 0.6718 - val_accuracy: 0.7819\n",
      "Epoch 24/30\n",
      "281/281 [==============================] - 345s 1s/step - loss: 0.4481 - accuracy: 0.8394 - val_loss: 0.6512 - val_accuracy: 0.7757\n",
      "Epoch 25/30\n",
      "281/281 [==============================] - 358s 1s/step - loss: 0.3988 - accuracy: 0.8529 - val_loss: 0.5701 - val_accuracy: 0.8104\n",
      "Epoch 26/30\n",
      "281/281 [==============================] - 304s 1s/step - loss: 0.3571 - accuracy: 0.8733 - val_loss: 0.5009 - val_accuracy: 0.8358\n",
      "Epoch 27/30\n",
      "281/281 [==============================] - 292s 1s/step - loss: 0.3221 - accuracy: 0.8841 - val_loss: 0.4743 - val_accuracy: 0.8460\n",
      "Epoch 28/30\n",
      "281/281 [==============================] - 321s 1s/step - loss: 0.3136 - accuracy: 0.8835 - val_loss: 0.5566 - val_accuracy: 0.8198\n",
      "Epoch 29/30\n",
      "281/281 [==============================] - 278s 990ms/step - loss: 0.2859 - accuracy: 0.8900 - val_loss: 0.4998 - val_accuracy: 0.8389\n",
      "Epoch 30/30\n",
      "281/281 [==============================] - 293s 1s/step - loss: 0.2647 - accuracy: 0.9029 - val_loss: 0.4642 - val_accuracy: 0.8576\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9\n",
    "\n",
    "# Model - Rescaling -> Conv2D -> MaxPooling2D -> Dropout -> Conv2D -> MaxPooling2D -> Dropout -> Conv2D -> MaxPooling2D -> Dropout -> Dense -> Dense\n",
    "model = Sequential()\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "model.add(Conv2D(16, 3, padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, 3, padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding='same'))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss = SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "169/169 [==============================] - 157s 724ms/step - loss: 2.2131 - accuracy: 0.1409 - val_loss: 2.2019 - val_accuracy: 0.1336\n",
      "Epoch 2/30\n",
      "169/169 [==============================] - 164s 973ms/step - loss: 2.1838 - accuracy: 0.1341 - val_loss: 2.2007 - val_accuracy: 0.1359\n",
      "Epoch 3/30\n",
      "169/169 [==============================] - 165s 979ms/step - loss: 2.1793 - accuracy: 0.1443 - val_loss: 2.1834 - val_accuracy: 0.1470\n",
      "Epoch 4/30\n",
      "169/169 [==============================] - 185s 1s/step - loss: 2.1692 - accuracy: 0.1538 - val_loss: 2.1434 - val_accuracy: 0.1960\n",
      "Epoch 5/30\n",
      "169/169 [==============================] - 172s 1s/step - loss: 2.0299 - accuracy: 0.2482 - val_loss: 2.0701 - val_accuracy: 0.1908\n",
      "Epoch 6/30\n",
      "169/169 [==============================] - 138s 813ms/step - loss: 1.9082 - accuracy: 0.2717 - val_loss: 2.0267 - val_accuracy: 0.1960\n",
      "Epoch 7/30\n",
      "169/169 [==============================] - 106s 625ms/step - loss: 1.8395 - accuracy: 0.2635 - val_loss: 2.1831 - val_accuracy: 0.1648\n",
      "Epoch 8/30\n",
      "169/169 [==============================] - 109s 646ms/step - loss: 1.7850 - accuracy: 0.2973 - val_loss: 2.1435 - val_accuracy: 0.1641\n",
      "Epoch 9/30\n",
      "169/169 [==============================] - 108s 637ms/step - loss: 1.7633 - accuracy: 0.3251 - val_loss: 1.9228 - val_accuracy: 0.2569\n",
      "Epoch 10/30\n",
      "169/169 [==============================] - 117s 690ms/step - loss: 1.7574 - accuracy: 0.3219 - val_loss: 2.2551 - val_accuracy: 0.1886\n",
      "Epoch 11/30\n",
      "169/169 [==============================] - 118s 699ms/step - loss: 1.7418 - accuracy: 0.3270 - val_loss: 1.9539 - val_accuracy: 0.2598\n",
      "Epoch 12/30\n",
      "169/169 [==============================] - 113s 667ms/step - loss: 1.7107 - accuracy: 0.3309 - val_loss: 2.2779 - val_accuracy: 0.1997\n",
      "Epoch 13/30\n",
      "169/169 [==============================] - 109s 646ms/step - loss: 1.7083 - accuracy: 0.3336 - val_loss: 1.9412 - val_accuracy: 0.2687\n",
      "Epoch 14/30\n",
      "169/169 [==============================] - 113s 669ms/step - loss: 1.6951 - accuracy: 0.3552 - val_loss: 1.9167 - val_accuracy: 0.2829\n",
      "Epoch 15/30\n",
      "169/169 [==============================] - 163s 967ms/step - loss: 1.7004 - accuracy: 0.3549 - val_loss: 2.0678 - val_accuracy: 0.2390\n",
      "Epoch 16/30\n",
      "169/169 [==============================] - 258s 2s/step - loss: 1.6986 - accuracy: 0.3508 - val_loss: 2.0819 - val_accuracy: 0.2183\n",
      "Epoch 17/30\n",
      "169/169 [==============================] - 327s 2s/step - loss: 1.7068 - accuracy: 0.3412 - val_loss: 2.0553 - val_accuracy: 0.2227\n",
      "Epoch 18/30\n",
      "169/169 [==============================] - 320s 2s/step - loss: 1.7029 - accuracy: 0.3399 - val_loss: 1.9984 - val_accuracy: 0.2450\n",
      "Epoch 19/30\n",
      "169/169 [==============================] - 276s 2s/step - loss: 1.7059 - accuracy: 0.3283 - val_loss: 2.1386 - val_accuracy: 0.2042\n",
      "Epoch 20/30\n",
      "169/169 [==============================] - 321s 2s/step - loss: 1.7089 - accuracy: 0.3431 - val_loss: 2.0493 - val_accuracy: 0.2502\n",
      "Epoch 21/30\n",
      "169/169 [==============================] - 307s 2s/step - loss: 1.6908 - accuracy: 0.3524 - val_loss: 2.1090 - val_accuracy: 0.2153\n",
      "Epoch 22/30\n",
      "169/169 [==============================] - 375s 2s/step - loss: 1.6731 - accuracy: 0.3531 - val_loss: 1.8016 - val_accuracy: 0.3051\n",
      "Epoch 23/30\n",
      "169/169 [==============================] - 353s 2s/step - loss: 1.6856 - accuracy: 0.3504 - val_loss: 1.8513 - val_accuracy: 0.2895\n",
      "Epoch 24/30\n",
      "169/169 [==============================] - 389s 2s/step - loss: 1.6737 - accuracy: 0.3541 - val_loss: 2.0029 - val_accuracy: 0.2591\n",
      "Epoch 25/30\n",
      "169/169 [==============================] - 197s 1s/step - loss: 1.6873 - accuracy: 0.3435 - val_loss: 1.9854 - val_accuracy: 0.2658\n",
      "Epoch 26/30\n",
      "169/169 [==============================] - 184s 1s/step - loss: 1.6877 - accuracy: 0.3516 - val_loss: 1.9604 - val_accuracy: 0.2717\n",
      "Epoch 27/30\n",
      "169/169 [==============================] - 192s 1s/step - loss: 1.6661 - accuracy: 0.3553 - val_loss: 2.0845 - val_accuracy: 0.2235\n",
      "Epoch 28/30\n",
      "169/169 [==============================] - 175s 1s/step - loss: 1.6856 - accuracy: 0.3447 - val_loss: 2.0528 - val_accuracy: 0.2294\n",
      "Epoch 29/30\n",
      "169/169 [==============================] - 172s 1s/step - loss: 1.6881 - accuracy: 0.3391 - val_loss: 1.9829 - val_accuracy: 0.2480\n",
      "Epoch 30/30\n",
      "169/169 [==============================] - 186s 1s/step - loss: 1.6942 - accuracy: 0.3466 - val_loss: 1.9911 - val_accuracy: 0.2428\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "bitmap \"class.ico\" not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7d2a908b1442>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Portable Image Classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miconbitmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'class.ico'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresizable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Portable Image Classifier\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpady\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mwm_iconbitmap\u001b[1;34m(self, bitmap, default)\u001b[0m\n\u001b[0;32m   2069\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'iconbitmap'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2070\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'iconbitmap'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbitmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2073\u001b[0m     \u001b[0miconbitmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwm_iconbitmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTclError\u001b[0m: bitmap \"class.ico\" not defined"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.title('Portable Image Classifier')\n",
    "root.iconbitmap('class.ico')\n",
    "root.resizable(False, False)\n",
    "tit = tk.Label(root, text=\"Portable Image Classifier\", padx=25, pady=6, font=(\"\", 12)).pack()\n",
    "canvas = tk.Canvas(root, height=500, width=500, bg='grey')\n",
    "canvas.pack()\n",
    "frame = tk.Frame(root, bg='white')\n",
    "frame.place(relwidth=0.8, relheight=0.8, relx=0.1, rely=0.1)\n",
    "chose_image = tk.Button(root, text='Choose Image',\n",
    "                        padx=35, pady=10,\n",
    "                        fg=\"white\", bg=\"grey\", command=load_img)\n",
    "chose_image.pack(side=tk.LEFT)\n",
    "class_image = tk.Button(root, text='Classify Image',\n",
    "                        padx=35, pady=10,\n",
    "                        fg=\"white\", bg=\"grey\", command=classify)\n",
    "class_image.pack(side=tk.RIGHT)\n",
    "vgg_model = vgg16.VGG16(weights='imagenet')\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
